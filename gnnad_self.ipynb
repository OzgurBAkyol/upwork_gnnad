{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-05T10:28:07.082580Z",
     "start_time": "2024-10-05T10:27:30.742632Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def combine_csv_files(input_path, output_file, sort_column):\n",
    "    all_files = glob.glob(input_path)\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "\n",
    "    combined_df = pd.concat(df_list)\n",
    "    combined_df.sort_values(by=sort_column, inplace=True)\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "file_path = './Datasets/*.csv'\n",
    "output_file = 'combined.csv'\n",
    "sort_column = 'timestamp'\n",
    "\n",
    "combined_df = combine_csv_files(file_path, output_file, sort_column)\n",
    "print(combined_df.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               timestamp sensor  pm10  pm25  pm25_avg_15  \\\n",
      "175455  2023-09-30 18:30:27.774598+00:00      a  1.42  5.79         5.29   \n",
      "175454  2023-09-30 18:30:27.920222+00:00      b  0.87  5.56         5.08   \n",
      "175455  2023-09-30 18:30:28.154017+00:00      a  0.00  2.67         2.34   \n",
      "175454  2023-09-30 18:30:28.323640+00:00      b  1.16  3.51         3.24   \n",
      "175457  2023-09-30 18:30:29.796207+00:00      a  1.51  3.76         3.34   \n",
      "\n",
      "        pm25_avg_60  pm100  \n",
      "175455         5.38   2.12  \n",
      "175454         5.22   2.20  \n",
      "175455         2.58   0.00  \n",
      "175454         3.38   2.52  \n",
      "175457         3.05   2.11  \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:28:15.578528Z",
     "start_time": "2024-10-05T10:28:08.595985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_k = pd.read_csv('combined.csv')\n",
    "data_k.info()"
   ],
   "id": "e8141b14f956ed5c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7193905 entries, 0 to 7193904\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   timestamp    object \n",
      " 1   sensor       object \n",
      " 2   pm10         float64\n",
      " 3   pm25         float64\n",
      " 4   pm25_avg_15  float64\n",
      " 5   pm25_avg_60  float64\n",
      " 6   pm100        float64\n",
      "dtypes: float64(5), object(2)\n",
      "memory usage: 384.2+ MB\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:28:15.946194Z",
     "start_time": "2024-10-05T10:28:15.732726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_k_filtered = data_k[['timestamp', 'sensor', 'pm25_avg_60']]\n",
    "\n",
    "print(data_k_filtered)"
   ],
   "id": "d7633a1a0c2f787",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                timestamp sensor  pm25_avg_60\n",
      "0        2023-09-30 18:30:27.774598+00:00      a         5.38\n",
      "1        2023-09-30 18:30:27.920222+00:00      b         5.22\n",
      "2        2023-09-30 18:30:28.154017+00:00      a         2.58\n",
      "3        2023-09-30 18:30:28.323640+00:00      b         3.38\n",
      "4        2023-09-30 18:30:29.796207+00:00      a         3.05\n",
      "...                                   ...    ...          ...\n",
      "7193900  2024-01-30 18:28:45.059066+00:00      b        21.10\n",
      "7193901  2024-01-30 18:28:46.464060+00:00      a        25.21\n",
      "7193902  2024-01-30 18:28:46.627388+00:00      b        24.28\n",
      "7193903  2024-01-30 18:28:46.887233+00:00      a         2.88\n",
      "7193904  2024-01-30 18:28:47.107943+00:00      b         2.70\n",
      "\n",
      "[7193905 rows x 3 columns]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:28:15.987475Z",
     "start_time": "2024-10-05T10:28:15.980961Z"
    }
   },
   "cell_type": "code",
   "source": "data_k_filtered.info()",
   "id": "bee89c0bf0c484c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7193905 entries, 0 to 7193904\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   timestamp    object \n",
      " 1   sensor       object \n",
      " 2   pm25_avg_60  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 164.7+ MB\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:28:20.064736Z",
     "start_time": "2024-10-05T10:28:16.021070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data_k = pd.read_csv('your_file.csv')\n",
    "\n",
    "data_k_filtered['timestamp'] = pd.to_datetime(data_k_filtered['timestamp'])\n",
    "hourly_avg = data_k_filtered.resample('H', on='timestamp').mean().reset_index()\n",
    "\n",
    "#hourly_avg = hourly_avg.drop(columns=['sensor'])\n",
    "print(hourly_avg)"
   ],
   "id": "d8645e8678cfa64c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/11d0bknx2ms1fxq4p99sr8tc0000gn/T/ipykernel_3980/2806714021.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_k_filtered['timestamp'] = pd.to_datetime(data_k_filtered['timestamp'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     timestamp  pm25_avg_60\n",
      "0    2023-09-30 18:00:00+00:00    41.616528\n",
      "1    2023-09-30 19:00:00+00:00    36.003630\n",
      "2    2023-09-30 20:00:00+00:00    30.158171\n",
      "3    2023-09-30 21:00:00+00:00    33.766772\n",
      "4    2023-09-30 22:00:00+00:00    25.516443\n",
      "...                        ...          ...\n",
      "2924 2024-01-30 14:00:00+00:00    25.539407\n",
      "2925 2024-01-30 15:00:00+00:00    25.034394\n",
      "2926 2024-01-30 16:00:00+00:00    23.633642\n",
      "2927 2024-01-30 17:00:00+00:00    23.616841\n",
      "2928 2024-01-30 18:00:00+00:00    25.828821\n",
      "\n",
      "[2929 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/11d0bknx2ms1fxq4p99sr8tc0000gn/T/ipykernel_3980/2806714021.py:11: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  hourly_avg = data_k_filtered.resample('H', on='timestamp').mean().reset_index()\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:28:20.105284Z",
     "start_time": "2024-10-05T10:28:20.097725Z"
    }
   },
   "cell_type": "code",
   "source": "hourly_avg.info()",
   "id": "f6b3c9a1b49baac9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2929 entries, 0 to 2928\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype              \n",
      "---  ------       --------------  -----              \n",
      " 0   timestamp    2929 non-null   datetime64[ns, UTC]\n",
      " 1   pm25_avg_60  2929 non-null   float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(1)\n",
      "memory usage: 45.9 KB\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:28:20.148314Z",
     "start_time": "2024-10-05T10:28:20.142406Z"
    }
   },
   "cell_type": "code",
   "source": "hourly_avg.head()",
   "id": "9229f15e815aacae",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  timestamp  pm25_avg_60\n",
       "0 2023-09-30 18:00:00+00:00    41.616528\n",
       "1 2023-09-30 19:00:00+00:00    36.003630\n",
       "2 2023-09-30 20:00:00+00:00    30.158171\n",
       "3 2023-09-30 21:00:00+00:00    33.766772\n",
       "4 2023-09-30 22:00:00+00:00    25.516443"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>pm25_avg_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-30 18:00:00+00:00</td>\n",
       "      <td>41.616528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-30 19:00:00+00:00</td>\n",
       "      <td>36.003630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-09-30 20:00:00+00:00</td>\n",
       "      <td>30.158171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-09-30 21:00:00+00:00</td>\n",
       "      <td>33.766772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-09-30 22:00:00+00:00</td>\n",
       "      <td>25.516443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:28:20.228891Z",
     "start_time": "2024-10-05T10:28:20.205673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wind = pd.read_csv('fresno_wind.csv')\n",
    "wind.head()"
   ],
   "id": "a4bd6fc6ad2fddf2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     name             datetime  temp  feelslike   dew  humidity  precip  \\\n",
       "0  fresno  2023-10-01T00:00:00  15.6       15.6  10.0     69.18     0.0   \n",
       "1  fresno  2023-10-01T01:00:00  14.3       14.3   9.9     75.29     0.0   \n",
       "2  fresno  2023-10-01T02:00:00  14.3       14.3  10.0     75.41     0.0   \n",
       "3  fresno  2023-10-01T03:00:00  14.2       14.2  10.0     75.60     0.0   \n",
       "4  fresno  2023-10-01T04:00:00  14.2       14.2  10.0     75.65     0.0   \n",
       "\n",
       "   precipprob preciptype  snow  ...  sealevelpressure  cloudcover  visibility  \\\n",
       "0           0        NaN     0  ...            1008.8        86.3        16.0   \n",
       "1           0        NaN     0  ...            1009.0        87.1        16.0   \n",
       "2           0        NaN     0  ...            1009.2        87.3        16.0   \n",
       "3           0        NaN     0  ...            1009.2        86.3        16.0   \n",
       "4           0        NaN     0  ...            1009.3        52.2        16.0   \n",
       "\n",
       "   solarradiation  solarenergy  uvindex  severerisk        conditions  \\\n",
       "0               1          0.0        0          10  Partially cloudy   \n",
       "1               1          0.0        0          10  Partially cloudy   \n",
       "2               0          0.0        0          10  Partially cloudy   \n",
       "3               0          0.0        0          10  Partially cloudy   \n",
       "4               0          0.0        0          10  Partially cloudy   \n",
       "\n",
       "                  icon                                           stations  \n",
       "0  partly-cloudy-night  CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...  \n",
       "1  partly-cloudy-night  CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...  \n",
       "2  partly-cloudy-night  CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...  \n",
       "3  partly-cloudy-night  CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...  \n",
       "4  partly-cloudy-night  CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp</th>\n",
       "      <th>feelslike</th>\n",
       "      <th>dew</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precip</th>\n",
       "      <th>precipprob</th>\n",
       "      <th>preciptype</th>\n",
       "      <th>snow</th>\n",
       "      <th>...</th>\n",
       "      <th>sealevelpressure</th>\n",
       "      <th>cloudcover</th>\n",
       "      <th>visibility</th>\n",
       "      <th>solarradiation</th>\n",
       "      <th>solarenergy</th>\n",
       "      <th>uvindex</th>\n",
       "      <th>severerisk</th>\n",
       "      <th>conditions</th>\n",
       "      <th>icon</th>\n",
       "      <th>stations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fresno</td>\n",
       "      <td>2023-10-01T00:00:00</td>\n",
       "      <td>15.6</td>\n",
       "      <td>15.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>69.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>86.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fresno</td>\n",
       "      <td>2023-10-01T01:00:00</td>\n",
       "      <td>14.3</td>\n",
       "      <td>14.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>75.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>87.1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fresno</td>\n",
       "      <td>2023-10-01T02:00:00</td>\n",
       "      <td>14.3</td>\n",
       "      <td>14.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>87.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fresno</td>\n",
       "      <td>2023-10-01T03:00:00</td>\n",
       "      <td>14.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>86.3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fresno</td>\n",
       "      <td>2023-10-01T04:00:00</td>\n",
       "      <td>14.2</td>\n",
       "      <td>14.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>75.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1009.3</td>\n",
       "      <td>52.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Partially cloudy</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>CI080,KMAE,74504693242,74702023110,KNLC,KFAT,7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:28:20.296191Z",
     "start_time": "2024-10-05T10:28:20.279830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# hourly_avg = pd.read_csv('hourly_avg.csv')\n",
    "# wind = pd.read_csv('wind.csv')\n",
    "\n",
    "hourly_avg['timestamp'] = pd.to_datetime(hourly_avg['timestamp'])\n",
    "\n",
    "wind['datetime'] = pd.to_datetime(wind['datetime']).dt.tz_localize('UTC')\n",
    "\n",
    "merged_data = pd.merge(hourly_avg, wind[['datetime', 'windspeed', 'winddir']], left_on='timestamp', right_on='datetime', how='inner')\n",
    "\n",
    "merged_data = merged_data.drop(columns=['datetime'])\n",
    "\n",
    "print(merged_data)"
   ],
   "id": "fd5da2ab9b7edc2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     timestamp  pm25_avg_60  windspeed  winddir\n",
      "0    2023-10-01 00:00:00+00:00    24.862980       14.2      329\n",
      "1    2023-10-01 01:00:00+00:00    24.941687        9.2      329\n",
      "2    2023-10-01 02:00:00+00:00    25.208467        5.5      342\n",
      "3    2023-10-01 03:00:00+00:00    25.591894        0.3        3\n",
      "4    2023-10-01 04:00:00+00:00    30.816927        0.2        5\n",
      "...                        ...          ...        ...      ...\n",
      "2919 2024-01-30 14:00:00+00:00    25.539407        7.8      112\n",
      "2920 2024-01-30 15:00:00+00:00    25.034394        7.8      140\n",
      "2921 2024-01-30 16:00:00+00:00    23.633642        9.4      121\n",
      "2922 2024-01-30 17:00:00+00:00    23.616841        9.4      121\n",
      "2923 2024-01-30 18:00:00+00:00    25.828821        7.4      109\n",
      "\n",
      "[2924 rows x 4 columns]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T01:30:48.607149Z",
     "start_time": "2024-10-05T01:30:48.586807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(data, target_column, test_size=0.2, val_size=0.5, random_state=42):\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(\n",
    "    merged_data,\n",
    "    target_column='pm25_avg_60',\n",
    "    test_size=0.13,\n",
    "    val_size=0.6923,\n",
    "    random_state=42\n",
    ")"
   ],
   "id": "426979ad392989be",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T01:30:50.499087Z",
     "start_time": "2024-10-05T01:30:50.495430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ],
   "id": "987f1c5379a7f206",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T02:07:44.496033Z",
     "start_time": "2024-10-05T02:07:44.451369Z"
    }
   },
   "cell_type": "code",
   "source": "merged_data.info()",
   "id": "eaeb6f19808acce6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2924 entries, 0 to 2923\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype              \n",
      "---  ------       --------------  -----              \n",
      " 0   timestamp    2924 non-null   datetime64[ns, UTC]\n",
      " 1   pm25_avg_60  2924 non-null   float64            \n",
      " 2   windspeed    2924 non-null   float64            \n",
      " 3   winddir      2924 non-null   int64              \n",
      "dtypes: datetime64[ns, UTC](1), float64(2), int64(1)\n",
      "memory usage: 178.8 KB\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T11:27:05.068398Z",
     "start_time": "2024-10-05T11:26:18.492822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def load_and_preprocess_data(file_path, wind_file, features, target_column, test_size=0.2, random_state=42):\n",
    "    all_files = glob.glob(file_path)\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "    combined_df = pd.concat(df_list)\n",
    "    combined_df.sort_values(by='timestamp', inplace=True)\n",
    "    combined_df.to_csv('combined.csv', index=False)\n",
    "\n",
    "    data_k = pd.read_csv('combined.csv')\n",
    "    data_k['timestamp'] = pd.to_datetime(data_k['timestamp'])\n",
    "    hourly_avg = data_k.resample('H', on='timestamp').mean().reset_index()\n",
    "\n",
    "    wind = pd.read_csv(wind_file)\n",
    "    wind['datetime'] = pd.to_datetime(wind['datetime']).dt.tz_localize('UTC')\n",
    "    merged_data = pd.merge(hourly_avg, wind[['datetime', 'windspeed', 'winddir']],\n",
    "                           left_on='timestamp', right_on='datetime', how='inner')\n",
    "    merged_data = merged_data.drop(columns=['datetime'])\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    merged_data[features] = scaler.fit_transform(merged_data[features])\n",
    "\n",
    "    labels = np.zeros(merged_data.shape[0], dtype=int)\n",
    "    num_anomalies = int(0.05 * merged_data.shape[0])\n",
    "    anomaly_indices = np.random.choice(merged_data.index, num_anomalies, replace=False)\n",
    "    labels[anomaly_indices] = 1\n",
    "\n",
    "    data = torch.tensor(merged_data[features].values, dtype=torch.float32)\n",
    "    labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    return train_test_split(data, labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def train_model(X_train, y_train, input_size, num_epochs=50, learning_rate=0.001):\n",
    "    class SimpleNN(nn.Module):\n",
    "        def __init__(self, input_size):\n",
    "            super(SimpleNN, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, 128)\n",
    "            self.fc2 = nn.Linear(128, 64)\n",
    "            self.fc3 = nn.Linear(64, 32)\n",
    "            self.fc4 = nn.Linear(32, 2)\n",
    "            self.dropout = nn.Dropout(p=0.5)\n",
    "            self.bn1 = nn.BatchNorm1d(128)\n",
    "            self.bn2 = nn.BatchNorm1d(64)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.bn1(self.fc1(x)))\n",
    "            x = self.dropout(x)\n",
    "            x = torch.relu(self.bn2(self.fc2(x)))\n",
    "            x = self.dropout(x)\n",
    "            x = torch.relu(self.fc3(x))\n",
    "            x = self.fc4(x)\n",
    "            return x\n",
    "\n",
    "    model = SimpleNN(input_size)\n",
    "    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.5, 2.0]))\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    return model\n",
    "\n",
    "class AnomalyGenerator:\n",
    "    def __init__(self, model, eps=0.1, alpha=0.01, steps=10, random_start=True):\n",
    "        self.model = model\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "        self.steps = steps\n",
    "        self.random_start = random_start\n",
    "\n",
    "    def fgsm(self, data, labels):\n",
    "        data = data.clone().detach().requires_grad_(True)\n",
    "        outputs = self.model(data)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        grad = torch.autograd.grad(loss, data)[0]\n",
    "        adv_data = data + self.eps * grad.sign()\n",
    "        return torch.clamp(adv_data, min=0, max=1)\n",
    "\n",
    "    def generate_anomalies(self, data, labels, method='fgsm'):\n",
    "        if method == 'fgsm':\n",
    "            return self.fgsm(data, labels)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        _, predicted = torch.max(test_outputs.data, 1)\n",
    "    print(classification_report(y_test, predicted.numpy(), target_names=['Normal', 'Anomali']))\n",
    "\n",
    "file_path = './Datasets/*.csv'\n",
    "wind_file = 'fresno_wind.csv'\n",
    "features = ['pm25_avg_60', 'windspeed', 'winddir']\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_and_preprocess_data(file_path, wind_file, features, 'pm25_avg_60')\n",
    "model = train_model(X_train, y_train, input_size=X_train.shape[1])\n",
    "evaluate_model(model, X_test, y_test)\n",
    "\n",
    "anomaly_gen = AnomalyGenerator(model)\n",
    "X_test_adv = anomaly_gen.generate_anomalies(X_test, y_test)"
   ],
   "id": "635fee2148c0e5ca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vr/11d0bknx2ms1fxq4p99sr8tc0000gn/T/ipykernel_3980/3349365858.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_k_filtered['timestamp'] = pd.to_datetime(data_k_filtered['timestamp'])\n",
      "/var/folders/vr/11d0bknx2ms1fxq4p99sr8tc0000gn/T/ipykernel_3980/3349365858.py:33: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  hourly_avg = data_k_filtered.resample('H', on='timestamp').mean().reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.95      0.98      0.96       556\n",
      "     Anomali       0.08      0.03      0.05        29\n",
      "\n",
      "    accuracy                           0.93       585\n",
      "   macro avg       0.51      0.51      0.51       585\n",
      "weighted avg       0.91      0.93      0.92       585\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T02:14:34.047434Z",
     "start_time": "2024-10-05T02:14:33.919823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "class AnomalyGenerator:\n",
    "    def __init__(self, model, eps=8 / 255, alpha=2 / 255, steps=10, random_start=True):\n",
    "        self.model = model\n",
    "        self.eps = eps\n",
    "        self.alpha = alpha\n",
    "        self.steps = steps\n",
    "        self.random_start = random_start\n",
    "\n",
    "    def fgsm(self, data, labels):\n",
    "        data = data.clone().detach().requires_grad_(True)\n",
    "        outputs = self.model(data)\n",
    "        loss = nn.BCELoss()(outputs, labels)\n",
    "        grad = torch.autograd.grad(loss, data)[0]\n",
    "        adv_data = data + self.eps * grad.sign()\n",
    "        return torch.clamp(adv_data, min=0, max=1)\n",
    "\n",
    "    def generate_anomalies(self, data, labels, method='fgsm'):\n",
    "        if method == 'fgsm':\n",
    "            return self.fgsm(data, labels)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "\n",
    "class AnomalyDetectionModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(AnomalyDetectionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "def prepare_data(data, features, anomaly_frac=0.1, random_state=42):\n",
    "    anomaly_data = data.sample(frac=anomaly_frac, random_state=random_state)\n",
    "    anomaly_labels = np.ones(anomaly_data.shape[0], dtype=int)\n",
    "\n",
    "    normal_data = data.drop(anomaly_data.index)\n",
    "    normal_labels = np.zeros(normal_data.shape[0], dtype=int)\n",
    "\n",
    "    X = pd.concat([normal_data, anomaly_data])\n",
    "    y = np.concatenate([normal_labels, anomaly_labels])\n",
    "\n",
    "    X, y = shuffle(X, y, random_state=random_state)\n",
    "    return X[features].values, y\n",
    "\n",
    "def train_model(X_train, y_train, input_size, num_epochs=100, learning_rate=0.001):\n",
    "    model = AnomalyDetectionModel(input_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        inputs = torch.FloatTensor(X_train)\n",
    "        labels = torch.FloatTensor(y_train).view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, anomaly_gen, method='fgsm'):\n",
    "    adv_data = anomaly_gen.generate_anomalies(torch.FloatTensor(X_test), torch.FloatTensor(y_test).view(-1, 1), method=method)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(adv_data)\n",
    "        predicted = (test_outputs > 0.5).float()\n",
    "    print(classification_report(y_test, predicted.numpy(), target_names=['Normal', 'Anomali'], zero_division=0))\n",
    "\n",
    "features = ['pm25_avg_60', 'windspeed', 'winddir']\n",
    "X, y = prepare_data(merged_data, features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = train_model(X_train, y_train, input_size=X_train.shape[1])\n",
    "\n",
    "anomaly_gen = AnomalyGenerator(model)\n",
    "evaluate_model(model, X_test, y_test, anomaly_gen, method='fgsm')"
   ],
   "id": "b242ee7b26d655fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.4229\n",
      "Epoch [20/100], Loss: 0.3792\n",
      "Epoch [30/100], Loss: 0.3563\n",
      "Epoch [40/100], Loss: 0.3520\n",
      "Epoch [50/100], Loss: 0.3495\n",
      "Epoch [60/100], Loss: 0.3466\n",
      "Epoch [70/100], Loss: 0.3446\n",
      "Epoch [80/100], Loss: 0.3431\n",
      "Epoch [90/100], Loss: 0.3416\n",
      "Epoch [100/100], Loss: 0.3403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.91      1.00      0.95       532\n",
      "     Anomali       0.00      0.00      0.00        53\n",
      "\n",
      "    accuracy                           0.91       585\n",
      "   macro avg       0.45      0.50      0.48       585\n",
      "weighted avg       0.83      0.91      0.87       585\n",
      "\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9ba762e8cdd622d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
